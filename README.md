Fake News Detection: Hyperdimensional Computing (HDC) vs BERT
üìí üì∞ ü§ñ

Este reposit√≥rio apresenta uma compara√ß√£o entre algoritmos de Hyperdimensional Computing (HDC) e o modelo BERT aplicado ao problema de detec√ß√£o de fake news em um dataset rotulado (0 = n√£o fake, 1 = fake news). O objetivo √© avaliar o desempenho, interpretabilidade e complexidade de cada abordagem em cen√°rios pr√°ticos.

Notebooks do Projeto

‚Ä¢ Notebook 1: HDC com ngram encoder (BinHD & NeuralHD)

Implementa o encoder de n-gramas para representar textos em espa√ßos hiperdimensionais.
Avalia dois algoritmos: BinHD (baseado em opera√ß√µes bin√°rias) e NeuralHD (variante neuroinspirada).
Permite observar as diferen√ßas de desempenho e complexidade dos algoritmos HDC.
‚Ä¢ Notebook 2: HDC com ngram encoder + record encoder (BinHD)

Adiciona o uso do record encoder para enriquecer as representa√ß√µes hiperdimensionais.
Utiliza o algoritmo BinHD para classifica√ß√£o do texto como fake ou n√£o fake.
Compara os ganhos de performance com a arquitetura apenas com ngram encoder.
‚Ä¢ Notebook 3: BERT para Fake News

Usa o modelo BERT pr√©-treinado para classifica√ß√£o bin√°ria de not√≠cias falsas.
Efetua fine-tuning no mesmo dataset dos experimentos HDC.
Serve como baseline do estado da arte para compara√ß√£o com HDC.
Sobre o Dataset

O dataset cont√©m inicialmente 10000 linhas com not√≠cias reais e falsas.
Cada linha possui um texto (not√≠cia) e um r√≥tulo:
0 = Not√≠cia verdadeira
1 = Fake news
Objetivo

Comparar a simplicidade, desempenho e interpretabilidade entre m√©todos HDC e um Transformer (BERT) no contexto de fake news detection.
Auxiliar pesquisadores e entusiastas no entendimento pr√°tico dessas abordagens para NLP.
