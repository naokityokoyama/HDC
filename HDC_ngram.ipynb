{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1w6DaeJtOZZ9-lRqmb89BniMfnm7nQ8pH",
      "authorship_tag": "ABX9TyOEvRQ+PrAmh7xj/4Fa+7Th",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naokityokoyama/HDC/blob/main/HDC_ngram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-hd binhd unidecode num2words torchmetrics -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elF6JSBYPIGm",
        "outputId": "51417765-8846-4655-8ae3-44fe79eeb896",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.0/361.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.9/981.9 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from unidecode import unidecode\n",
        "import string\n",
        "from num2words import num2words\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Union, Literal\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torchhd\n",
        "from torchhd import embeddings\n",
        "\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from binhd.embeddings import ScatterCode\n",
        "from binhd.datasets import BaseDataset\n",
        "from binhd.classifiers import BinHD, NeuralHD\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "vK4UNRX3q6IA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_origin = '/content/drive/MyDrive/uff/fake.zip'\n",
        "path_destino = '/content/'\n",
        "with zipfile.ZipFile(path_origin, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(path_destino)"
      ],
      "metadata": {
        "id": "-fOH-CZGq4lU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build dataset\n",
        "\n",
        "df_fake = pd.read_csv('/content/fakes.csv')[['text']]\n",
        "df_fake['target'] = 1\n",
        "df_true = pd.read_csv('/content/true.csv')[['text']]\n",
        "df_true['target'] = 0\n",
        "df = pd.concat([df_fake, df_true]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "DnNOo-zVrdq3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o tamanho da amostra\n",
        "sample_size = 1000\n",
        "\n",
        "# Criar uma amostra balanceada\n",
        "df = df.groupby(\"target\", group_keys=False).apply(lambda x: resample(x, n_samples=sample_size // df[\"target\"].nunique(), random_state=42))\n",
        "df = df.reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "1Lje1PMs4wdS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "liaUwkRE48My",
        "outputId": "29c40f04-fdce-488b-bbb5-198a2341f395"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target\n",
              "0  Entre 2007 e 2016, cerca de 553 mil pessoas mo...       0\n",
              "1   As propinas descem pela primeira vez em 15 anos?       0\n",
              "2  O rendimento \"per capita\" dos portugueses é o ...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bbd52d1-a640-4d47-807b-181b784e2261\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Entre 2007 e 2016, cerca de 553 mil pessoas mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>As propinas descem pela primeira vez em 15 anos?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O rendimento \"per capita\" dos portugueses é o ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bbd52d1-a640-4d47-807b-181b784e2261')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9bbd52d1-a640-4d47-807b-181b784e2261 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9bbd52d1-a640-4d47-807b-181b784e2261');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7a3beed3-102b-4f5c-8adf-30dc9507c456\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a3beed3-102b-4f5c-8adf-30dc9507c456')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7a3beed3-102b-4f5c-8adf-30dc9507c456 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 943,\n        \"samples\": [\n          \"Ministra da Sa\\u00fade nega que Portugal seja um dos pa\\u00edses da UE que faz menos testes \\u00e0 Covid-19. Tem raz\\u00e3o? (Atualiza\\u00e7\\u00e3o)\",\n          \"Brasil saiu do 'Mapa da Fome' com Lula da Silva e Dilma Rousseff na presid\\u00eancia\",\n          \"\\\"URGENTE: A invas\\u00e3o hacker do TSE revela a fraude nas urnas com a chancela da justi\\u00e7a eleitoral. Os votos v\\u00e1lidos e os de quem justifica est\\u00e3o em banco de dados diferentes. Eles podem descarregar os votos de quem vai justificar na esquerda\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean"
      ],
      "metadata": {
        "id": "nmMGZTMjs-RI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def n2w(texto:str)->str:\n",
        "  padrao = r\"\\d+\"\n",
        "  numeros = re.findall(padrao, texto)\n",
        "  for numero in numeros:\n",
        "    extenso = num2words(numero, lang='pt')\n",
        "    texto = texto.replace(numero, extenso)\n",
        "  return texto"
      ],
      "metadata": {
        "id": "xvLhW4SgM8nz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for repet in tqdm(range(2)):  #bug para rodar 2x\n",
        "  df['text'] = df['text'].str.lower()\n",
        "  df['text'] = df['text'].str.replace(f\"[{string.punctuation}]\", \"\", regex=True)\n",
        "  df['text'] = df['text'].apply(lambda x: ' '.join(x.split()))\n",
        "  df['text'] = df['text'].str.replace('\"', '').str.replace('\\\\', '')\n",
        "  df['text'] = df['text'].apply(n2w)\n",
        "  df['text'] = df['text'].apply(unidecode)"
      ],
      "metadata": {
        "id": "pttxT5Jrr1rA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04eead19-6556-4006-aa4e-c109a9942c93"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 26.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'][8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vc4M_jh_xMaJ",
        "outputId": "4c08f049-fe71-461b-cf0a-f436183571ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'passamos para mais de trezentos trezentos e vinte cursos de medicina atualmente'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "MAX_INPUT_SIZE = 128\n",
        "PADDING_IDX = 0\n",
        "\n",
        "ASCII_A = ord(\"a\")\n",
        "ASCII_Z = ord(\"z\")\n",
        "ASCII_SPACE = ord(\" \")\n",
        "NUM_TOKENS = ASCII_Z - ASCII_A + 3  # a through z plus space and padding\n",
        "print (ASCII_A, '--', ASCII_Z, '--', ASCII_SPACE, '--', NUM_TOKENS)\n",
        "\n",
        "def char2int(char: str) -> int:\n",
        "    \"\"\"Map a character to its integer identifier\"\"\"\n",
        "    ascii_index = ord(char)\n",
        "\n",
        "    if ascii_index == ASCII_SPACE:\n",
        "        # Remap the space character to come after \"z\"\n",
        "        return ASCII_Z - ASCII_A + 1\n",
        "\n",
        "    return ascii_index - ASCII_A\n",
        "\n",
        "\n",
        "def transform(x: str) -> torch.Tensor:\n",
        "    char_ids = x[:MAX_INPUT_SIZE]\n",
        "    char_ids = [char2int(char) + 1 for char in char_ids.lower()]\n",
        "\n",
        "    if len(char_ids) < MAX_INPUT_SIZE:\n",
        "        char_ids += [PADDING_IDX] * (MAX_INPUT_SIZE - len(char_ids))\n",
        "\n",
        "    return torch.tensor(char_ids, dtype=torch.long)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJzdYjqKPWyF",
        "outputId": "50f6923e-c3bc-4cd7-d509-5cc3d28e02ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "97 -- 122 -- 32 -- 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create X and y\n",
        "lst = []\n",
        "print ('size dataset',df.shape[0] )\n",
        "for i in range(df.shape[0]):\n",
        "  lst.append (np.array(transform(df['text'][i])))\n",
        "\n",
        "X = np.array(lst)\n",
        "y = list(df['target'])\n"
      ],
      "metadata": {
        "id": "iWtPBZyaPUF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78018faf-000f-45e2-93df-f59958b12432"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size dataset 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6COVcI7IEUm",
        "outputId": "6cad6e85-9d81-4a06-e8ab-6af59016fc79"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5, 14, 20, ..., 27, 16,  1],\n",
              "       [ 1, 19, 27, ...,  0,  0,  0],\n",
              "       [15, 27, 18, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [16, 18, 15, ...,  0,  0,  0],\n",
              "       [21, 18,  7, ...,  0,  0,  0],\n",
              "       [20, 18, 21, ...,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DIMENSION = 1000\n",
        "NUM_LEVELS = 100 #usado no record encoding\n",
        "BATCH_SIZE = 100\n",
        "CLASSES = df['target'].nunique()\n",
        "\n",
        "min_val = float(X.min())\n",
        "max_val = float(X.max())\n",
        "\n",
        "SIZE = X.shape[1]\n",
        "print('val_min :', min_val, 'val_max :', max_val)\n",
        "\n",
        "accuracy = Accuracy(\"multiclass\", num_classes=CLASSES)\n",
        "model_BindHD = BinHD(DIMENSION, CLASSES)\n",
        "model_NeuralHD = NeuralHD(n_dimensions=128, n_classes=CLASSES, n_features=1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1VBskZUSQgd",
        "outputId": "a68f1925-6d47-4fe7-c699-f4260cce3ea6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_min : 0.0 val_max : 27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NgramEncoder(nn.Module):\n",
        "    def __init__(self, out_features, size):\n",
        "        super(NgramEncoder, self).__init__()\n",
        "        self.symbol = embeddings.Random(size, out_features, padding_idx=PADDING_IDX)\n",
        "        #print(self.symbol)\n",
        "    def forward(self, x):\n",
        "        #print (x, x.shape)\n",
        "        symbols = self.symbol(x)\n",
        "        sample_hv = torchhd.ngrams(symbols, n=4)  #colocar no construtor\n",
        "        return torchhd.normalize(sample_hv)\n",
        "\n",
        "encode = NgramEncoder(DIMENSION, NUM_TOKENS)\n",
        "encode = encode.to(device)"
      ],
      "metadata": {
        "id": "Jusuwe5Yyy-W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# with torch.no_grad():\n",
        "#     samples = torch.tensor(X).to(device)\n",
        "#     labels = torch.tensor(y).squeeze().to(device)\n",
        "\n",
        "#     X_hd = encode(samples)\n",
        "#     X_hd = X_hd.clip(0,1)\n",
        "#     X_Bind = X_hd.to(torch.int8)\n",
        "# X_train_, X_test_1, y_train, y_test = train_test_split(X_Bind, labels, test_size=0.30, random_state = 42)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_hd, labels, test_size=0.30, random_state = 42)\n",
        "\n"
      ],
      "metadata": {
        "id": "XfAKLG4EB6Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_BindHD = BinHD(DIMENSION, CLASSES)\n",
        "# with torch.no_grad():\n",
        "#     model_BindHD.fit(X_train_bind,y_train_bind)\n",
        "#     predictions = model_BindHD.predict(X_test_bind)\n",
        "#     acc = accuracy_score(predictions, y_test_bind)\n",
        "#     print(\"BinHD: Accuracy = \", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSGQUJVBqM2n",
        "outputId": "65d8ba28-e689-40e7-8a29-3ba955c1510f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BinHD: Accuracy =  0.5033333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_NeuralHD = NeuralHD(n_dimensions=128, n_classes=2, n_features=1000)\n",
        "# with torch.no_grad():\n",
        "#     model_NeuralHD.fit(X_train_Neural,y_train_Neural)\n",
        "#     predictions = model_NeuralHD.predict(X_test_Neural)\n",
        "#     acc = accuracy_score(predictions, y_test_Neural)\n",
        "#     print(\"NeuralHD: Accuracy = \", acc)"
      ],
      "metadata": {
        "id": "6wUUYxQvqKUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ativar\n",
        "# class RecordEncoder(nn.Module):\n",
        "#     def __init__(self, out_features, size, levels, low, high):\n",
        "#         super(RecordEncoder, self).__init__()\n",
        "#         self.position = embeddings.Random(size, out_features, vsa=\"BSC\", dtype=torch.uint8)\n",
        "#         self.value = ScatterCode(levels, out_features, low = low, high = high)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         sample_hv = torchhd.bind(self.position.weight, self.value(x))\n",
        "#         sample_hv = torchhd.multiset(sample_hv)\n",
        "#         return sample_hv\n",
        "\n",
        "# record_encode = RecordEncoder(DIMENSION, SIZE, NUM_LEVELS, min_val, max_val)\n",
        "# record_encode = record_encode.to(device)\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     samples = torch.tensor(X).to(device)\n",
        "#     labels = torch.tensor(y).squeeze().to(device)\n",
        "\n",
        "#     X_hv = record_encode(samples)\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_hv, labels, test_size=0.3, random_state = 0)\n",
        "\n",
        "# model = BinHD(DIMENSION, CLASSES)\n",
        "\n",
        "# with torch.no_grad():\n",
        "    # model.fit(X_train,y_train)\n",
        "    # predictions = model.predict(X_test)\n",
        "    # acc = accuracy_score(predictions, y_test)\n",
        "    # print(\"BinHD: Accuracy = \", acc)"
      ],
      "metadata": {
        "id": "-kzxu4hoP7U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch"
      ],
      "metadata": {
        "id": "UgdknenaxfRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class train_hdc:\n",
        "  def __init__(self, X: Union[float, int],\n",
        "               y: Union[float, int],\n",
        "               random:int = 42,\n",
        "               test_size:float = 0.30,\n",
        "               dimension:int=1000,\n",
        "               batch_size:int=1000,\n",
        "               classes:int=2,\n",
        "               features:int=128):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.random = random\n",
        "    self.test_size = test_size\n",
        "    self.dimension = dimension\n",
        "    self.batch_size = batch_size\n",
        "    self.classes = classes\n",
        "    self.features = features\n",
        "\n",
        "  def prepare_data(self)->str:\n",
        "    X = self.X\n",
        "    y = self.y\n",
        "    test_size = self.test_size\n",
        "    random = self.random\n",
        "    X_train_bind, X_test_bind, y_train_bind, y_test_bind = train_test_split(X, y, test_size=test_size, random_state =random)\n",
        "\n",
        "    train_dataset = BaseDataset(X_train_bind, y_train_bind)\n",
        "    test_dataset = BaseDataset(X_test_bind, y_test_bind)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "  def train(self, model_name:Literal['bindhd', 'neuralhd'])-> str:\n",
        "    #models\n",
        "    DIMENSION = self.dimension\n",
        "    CLASSES = self.classes\n",
        "    BATCH_SIZE = self.batch_size\n",
        "    FEATURES = self.features\n",
        "\n",
        "    model_BindHD = BinHD(DIMENSION, CLASSES)\n",
        "    model_NeuralHD = NeuralHD(n_dimensions=FEATURES, n_classes=CLASSES, n_features=DIMENSION)\n",
        "    if model_name == 'bindhd':\n",
        "      model = model_BindHD\n",
        "    elif model_name == 'neuralhd':\n",
        "      model = model_NeuralHD\n",
        "    else:\n",
        "      raise ValueError(\"Invalid model name provided. Choose 'bindhd' or 'neuralhd'.\")\n",
        "\n",
        "    #train BINHD\n",
        "    data_train = self.prepare_data()[0]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x_ , y_ in tqdm(data_train) :\n",
        "\n",
        "        samples = torch.tensor(x_).to(device)\n",
        "        labels = torch.tensor(y_).squeeze().to(device)\n",
        "        if model_name  == 'bindhd':\n",
        "          X_Bind = encode(samples)\n",
        "          X_Bind = X_Bind.clip(0,1) #\n",
        "          X_Bind = X_Bind.to(torch.int8)\n",
        "\n",
        "          model_BindHD.fit(X_Bind,labels)\n",
        "          trained_model = model_BindHD\n",
        "        else:\n",
        "          X_neural = encode(samples)\n",
        "          model_NeuralHD.fit(X_neural,labels)\n",
        "          trained_model = model_NeuralHD\n",
        "\n",
        "      return trained_model\n",
        "\n",
        "\n",
        "  def test(self, model:str)->str:\n",
        "    data_test = self.prepare_data()[1]\n",
        "    model_name = model.__class__.__name__\n",
        "\n",
        "    if model_name == 'BinHD':\n",
        "      model_BinHD = model\n",
        "      print ('model BinHD')\n",
        "    elif model_name == 'NeuralHD':\n",
        "      print ('model NeuralHD')\n",
        "      model_NeuralHD = model\n",
        "    else:\n",
        "      raise ValueError(\"Invalid model name provided. Choose 'bindhd' or 'neuralhd'.\")\n",
        "    with torch.no_grad():\n",
        "      for x_ , y_ in data_test:\n",
        "\n",
        "        samples = torch.tensor(x_).to(device)\n",
        "        labels = torch.tensor(y_).squeeze().to(device)\n",
        "\n",
        "        if model_name  == 'BinHD':\n",
        "          X_Bind = encode(samples)\n",
        "          #X_Bind = X_Bind.clip(0,1)\n",
        "          X_Bind = X_Bind.to(torch.int8)\n",
        "          predictions = model_BinHD.predict(X_Bind)\n",
        "          accuracy.update(predictions, labels)\n",
        "\n",
        "        elif model_name  == 'NeuralHD':\n",
        "          X_Neural = encode(samples)\n",
        "          predictions = model_NeuralHD.predict(X_Neural)\n",
        "          accuracy.update(predictions, labels)\n",
        "\n",
        "        else:\n",
        "          raise ValueError(\"Invalid model name provided. Choose 'bindhd' or 'neuralhd'.\")\n",
        "\n",
        "    acc = accuracy.compute().item()\n",
        "    print(f\"{model_name}: Accuracy = \", acc)"
      ],
      "metadata": {
        "id": "G-Abky80xByM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hdc = train_hdc(X, y)"
      ],
      "metadata": {
        "id": "AMJ8z7CUyQYZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "modelo_bindhd = hdc.train(model_name='bindhd')\n",
        "modelo_neuralhd= hdc.train(model_name='neuralhd')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaEYbIIrz8gt",
        "outputId": "8c8b40b9-c390-4ba2-a600-8d036b94c116",
        "collapsed": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:03<00:00,  2.32it/s]\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\n",
            "fit:   0%|          | 0/119 [00:00<?, ?it/s]\u001b[A\n",
            "fit:  38%|███▊      | 45/119 [00:00<00:00, 446.06it/s]\u001b[A\n",
            "fit: 100%|██████████| 119/119 [00:00<00:00, 547.75it/s]\n",
            " 14%|█▍        | 1/7 [00:00<00:03,  1.65it/s]\n",
            "fit:   0%|          | 0/119 [00:00<?, ?it/s]\u001b[A\n",
            "fit: 100%|██████████| 119/119 [00:00<00:00, 626.77it/s]\n",
            " 29%|██▊       | 2/7 [00:01<00:02,  1.72it/s]\n",
            "fit:   0%|          | 0/119 [00:00<?, ?it/s]\u001b[A\n",
            "fit: 100%|██████████| 119/119 [00:00<00:00, 574.99it/s]\n",
            " 43%|████▎     | 3/7 [00:01<00:02,  1.74it/s]\n",
            "fit:   0%|          | 0/119 [00:00<?, ?it/s]\u001b[A\n",
            "fit: 100%|██████████| 119/119 [00:00<00:00, 629.08it/s]\n",
            " 57%|█████▋    | 4/7 [00:02<00:01,  1.79it/s]\n",
            "fit:   0%|          | 0/119 [00:00<?, ?it/s]\u001b[A\n",
            "fit: 100%|██████████| 119/119 [00:00<00:00, 596.77it/s]\n",
            " 71%|███████▏  | 5/7 [00:02<00:01,  1.81it/s]\n",
            "fit:   0%|          | 0/119 [00:00<?, ?it/s]\u001b[A\n",
            "fit: 100%|██████████| 119/119 [00:00<00:00, 628.43it/s]\n",
            " 86%|████████▌ | 6/7 [00:03<00:00,  1.83it/s]\n",
            "fit:   0%|          | 0/119 [00:00<?, ?it/s]\u001b[A\n",
            "fit:  46%|████▌     | 55/119 [00:00<00:00, 548.79it/s]\u001b[A\n",
            "fit: 100%|██████████| 119/119 [00:00<00:00, 570.36it/s]\n",
            "100%|██████████| 7/7 [00:03<00:00,  1.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_bindhd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exuVHE1JxDpy",
        "outputId": "a5b05400-5272-4233-a422-d4b4a6d34cb4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BinHD()"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "hdc.test(model=modelo_bindhd)\n",
        "hdc.test(model=modelo_neuralhd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FEFoeeiAgcE",
        "outputId": "772cf56e-ccdb-47b1-fa33-c6bc04962dc9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model BinHD\n",
            "BinHD: Accuracy =  0.5166666507720947\n",
            "model NeuralHD\n",
            "NeuralHD: Accuracy =  0.5299999713897705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #train // test\n",
        "\n",
        "# X_train_bind, X_test_bind, y_train_bind, y_test_bind = train_test_split(X, y, test_size=0.30, random_state = 42)\n",
        "# train_dataset = BaseDataset(X_train_bind, y_train_bind)\n",
        "# test_dataset = BaseDataset(X_test_bind, y_test_bind)\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "NkSLoWfLRqe_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}