{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QeXphbvG_3Zqh5V4x80Kzi4qnAmSUrgF",
      "authorship_tag": "ABX9TyMx1oEvBCFuNJn7PKXiSkDG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naokityokoyama/HDC/blob/main/HDC_RecordEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHu1zFTXDP4Z"
      },
      "outputs": [],
      "source": [
        "!pip install torch-hd binhd unidecode num2words torchmetrics -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from unidecode import unidecode\n",
        "import string\n",
        "from num2words import num2words\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Union, Literal\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torchhd\n",
        "from torchhd import embeddings\n",
        "\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from binhd.embeddings import ScatterCode\n",
        "from binhd.datasets import BaseDataset\n",
        "from binhd.classifiers import BinHD, NeuralHD\n",
        "from torchmetrics import Accuracy, AUROC\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "8gw71xwDDXOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_origin = '/content/drive/MyDrive/uff/fake.zip'\n",
        "path_destino = '/content/'\n",
        "with zipfile.ZipFile(path_origin, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(path_destino)"
      ],
      "metadata": {
        "id": "OeOLo-1tDZes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build dataset\n",
        "\n",
        "df_fake = pd.read_csv('/content/fakes.csv')[['text']]\n",
        "df_fake['target'] = 1\n",
        "df_true = pd.read_csv('/content/true.csv')[['text']]\n",
        "df_true['target'] = 0\n",
        "df = pd.concat([df_fake, df_true]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "BpUoQG4XDbY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o tamanho da amostra\n",
        "sample_size = 10000\n",
        "\n",
        "# Criar uma amostra balanceada\n",
        "df = df.groupby(\"target\", group_keys=False).apply(lambda x: resample(x, n_samples=sample_size // df[\"target\"].nunique(), random_state=42))\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "FRJTtK56Dd3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "FeFlQjFHDgVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clean\n",
        "\n",
        "def n2w(texto:str)->str:\n",
        "  padrao = r\"\\d+\"\n",
        "  numeros = re.findall(padrao, texto)\n",
        "  for numero in numeros:\n",
        "    extenso = num2words(numero, lang='pt')\n",
        "    texto = texto.replace(numero, extenso)\n",
        "  return texto"
      ],
      "metadata": {
        "id": "mK_SZ8RPDiDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for repet in tqdm(range(2)):  #bug para rodar 2x\n",
        "  df['text'] = df['text'].str.lower()\n",
        "  df['text'] = df['text'].str.replace(f\"[{string.punctuation}]\", \"\", regex=True)\n",
        "  df['text'] = df['text'].apply(lambda x: ' '.join(x.split()))\n",
        "  df['text'] = df['text'].str.replace('\"', '').str.replace('\\\\', '')\n",
        "  df['text'] = df['text'].apply(n2w)\n",
        "  df['text'] = df['text'].apply(unidecode)"
      ],
      "metadata": {
        "id": "X5Ik5PWIDlEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "MAX_INPUT_SIZE = 128\n",
        "PADDING_IDX = 0\n",
        "\n",
        "ASCII_A = ord(\"a\")\n",
        "ASCII_Z = ord(\"z\")\n",
        "ASCII_SPACE = ord(\" \")\n",
        "NUM_TOKENS = ASCII_Z - ASCII_A + 3  # a through z plus space and padding\n",
        "print (ASCII_A, '--', ASCII_Z, '--', ASCII_SPACE, '--', NUM_TOKENS)\n",
        "\n",
        "def char2int(char: str) -> int:\n",
        "    \"\"\"Map a character to its integer identifier\"\"\"\n",
        "    ascii_index = ord(char)\n",
        "\n",
        "    if ascii_index == ASCII_SPACE:\n",
        "        # Remap the space character to come after \"z\"\n",
        "        return ASCII_Z - ASCII_A + 1\n",
        "\n",
        "    return ascii_index - ASCII_A\n",
        "\n",
        "\n",
        "def transform(x: str) -> torch.Tensor:\n",
        "    char_ids = x[:MAX_INPUT_SIZE]\n",
        "    char_ids = [char2int(char) + 1 for char in char_ids.lower()]\n",
        "\n",
        "    if len(char_ids) < MAX_INPUT_SIZE:\n",
        "        char_ids += [PADDING_IDX] * (MAX_INPUT_SIZE - len(char_ids))\n",
        "\n",
        "    return torch.tensor(char_ids, dtype=torch.long)"
      ],
      "metadata": {
        "id": "skTdkfZcDpKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create X and y\n",
        "lst = []\n",
        "print ('size dataset',df.shape[0] )\n",
        "for i in range(df.shape[0]):\n",
        "  lst.append (np.array(transform(df['text'][i])))\n",
        "\n",
        "X = np.array(lst)\n",
        "y = list(df['target'])"
      ],
      "metadata": {
        "id": "WAJzSDL-DrcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record Encoder"
      ],
      "metadata": {
        "id": "puSGtUF9D1PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "dimension = 1000\n",
        "num_levels = 100\n",
        "num_feature = X.shape[1]\n",
        "num_classe = len(set(np.array(y)))\n",
        "\n",
        "min_val = X[X != 0].min()\n",
        "max_val = X.max()\n",
        "print(min_val, max_val)\n",
        "\n",
        "class RecordEncoder(nn.Module):\n",
        "    def __init__(self, out_features, size, levels, low, high):\n",
        "        super(RecordEncoder, self).__init__()\n",
        "        self.position = embeddings.Random(size, out_features, vsa=\"BSC\", dtype=torch.uint8)\n",
        "        self.value = ScatterCode(levels, out_features, low = low, high = high)\n",
        "\n",
        "    def forward(self, x):\n",
        "        sample_hv = torchhd.bind(self.position.weight, self.value(x))\n",
        "        sample_hv = torchhd.multiset(sample_hv)\n",
        "        return sample_hv"
      ],
      "metadata": {
        "id": "KKLCZYdrD4NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record_encode = RecordEncoder(dimension, num_feature, num_levels, min_val, max_val)\n",
        "record_encode = record_encode.to(device)"
      ],
      "metadata": {
        "id": "Jz0eODE_EHLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    samples = torch.tensor(X).to(device)\n",
        "    labels = torch.tensor(y).squeeze().to(device)\n",
        "\n",
        "batch_size = 32\n",
        "num_samples = samples.shape[0]\n",
        "\n",
        "for i in tqdm(range(0, num_samples, batch_size)):\n",
        "    batch = samples[i:i+batch_size]\n",
        "    batch_labels = labels[i:i+batch_size]\n",
        "\n",
        "    X_hv = record_encode(batch)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_hv, batch_labels, test_size=0.3, random_state = 0)\n",
        "\n",
        "    model = BinHD(dimension, num_classe)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "      model.fit(X_train,y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "8bkuuXDYGUgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "acc = accuracy_score(predictions, y_test)\n",
        "print(\"BinHD - Adapt: Accuracy = \", acc)"
      ],
      "metadata": {
        "id": "uMWQAWITfZ_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = Accuracy(\"binary\", num_classes=2)\n",
        "auroc = AUROC(task=\"binary\")"
      ],
      "metadata": {
        "id": "PctqpEbwdFA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_value = auroc(predictions, y_test)\n",
        "accuracy = accuracy(predictions, y_test)\n",
        "print(\"BinHD - Adapt: AUC = \", acc_value, 'ACCURACY', accuracy)"
      ],
      "metadata": {
        "id": "XjJdDAn-HeU8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}